{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6eecd80-f8cf-439d-8a2b-d3833697e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 s ± 41.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "my_func             :    CPU:  531.215 us   +/-98.008 (min:  483.600 / max:  950.500) us     GPU-0:29382.161 us   +/-346.140 (min:28899.328 / max:30443.520) us\n"
     ]
    }
   ],
   "source": [
    "### https://carpentries-incubator.github.io/gpu-speedups/01_CuPy_and_Numba_on_the_GPU/index.html\n",
    "#### NUMBA CONFLICT WITH PYTORCH\n",
    "#### OSError: [WinError 182] The operating system cannot run %1. Error loading \n",
    "#### \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.\n",
    "##### =====> conda install intel-openmp --force-reinstall\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "memory_pool = cp.cuda.MemoryPool()\n",
    "cp.cuda.set_allocator(memory_pool.malloc)\n",
    "pinned_memory_pool = cp.cuda.PinnedMemoryPool()\n",
    "cp.cuda.set_pinned_memory_allocator(pinned_memory_pool.malloc)\n",
    "\n",
    "import cupyx.scipy.ndimage as ndimage_cp\n",
    "import scipy.ndimage as ndimage_np\n",
    "from cupyx.profiler import benchmark\n",
    "import scipy.ndimage as ndimage_np\n",
    "image1 = np.random.rand(100,1000,1000).astype(np.float32)\n",
    "image2 = cp.random.rand(100,1000,1000).astype(cp.float32)\n",
    "\n",
    "def my_func(a):\n",
    "    return ndimage_cp.zoom(a, (1, 0.1, 0.1))\n",
    "\n",
    "%timeit ndimage_np.zoom(image1, (1, 0.1, 0.1))\n",
    "print(benchmark(my_func, (image2,), n_repeat=20))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a038c6-b9e6-4f41-b9f4-3c881aeb3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "import numpy as np\n",
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['int64(int64, int64)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c1d8a44-41eb-4c5b-8dd2-5db3430a90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (1) < 2 * SM count (164) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.73574874e-224])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Gaussian distribution PDF a million times!\n",
    "x = np.random.uniform(-300, 300, size=100000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2656c4-db08-45be-8c9a-4cc45c1ff589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.83 ms ± 66.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "780c5d50-5d6c-4785-a430-8bccbc7614ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (131) < 2 * SM count (164) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97 ms ± 54.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d9411e-5097-4a0c-8106-b1fe3b269ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y  # This is Python, so let's return a tuple\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'], target='cuda')\n",
    "def polar_distance(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian(rho1, theta1)\n",
    "    x2, y2 = polar_to_cartesian(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64354a01-3caf-48c3-921d-ec49df9e1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rho1 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta1 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)\n",
    "rho2 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta2 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70d5db56-4703-45f0-90d7-c65dd12f9c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4676987 , 0.81071669, 1.73532505, ..., 1.38706656, 1.33927193,\n",
       "       1.50384252])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa5797c-74c5-4ea0-b00f-730002883a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def polar_to_cartesian_cpu(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y  # This is Python, so let's return a tuple\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'])  # default target is CPU\n",
    "def polar_distance_cpu(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian_cpu(rho1, theta1)\n",
    "    x2, y2 = polar_to_cartesian_cpu(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5\n",
    "\n",
    "np.testing.assert_allclose(polar_distance(rho1, theta1, rho2, theta2),\n",
    "                           polar_distance_cpu(rho1, theta1, rho2, theta2),\n",
    "                           rtol=1e-7, atol=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7da2d4-e38c-4740-8eba-c52f470ed605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.6 ms ± 728 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "11.4 ms ± 159 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit polar_distance_cpu(rho1, theta1, rho2, theta2)\n",
    "%timeit polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10694645-3ccb-4af9-8fcf-1ed7d1d78026",
   "metadata": {},
   "source": [
    "CuPy is NumPy, but for the GPU\n",
    "\n",
    "Data is copied from the CPU (host) to the GPU (device), where it is computed on. After a computation, it need to be copied back to the CPU to be interacted with by numpy, etc\n",
    "\n",
    "%timeit can be used to benchmark the runtime of GPU spedup functions\n",
    "\n",
    "GPU spedup functions are optimized for at least four things: 1. input size 2. compute complexity 3. CPU/GPU copying 4. data type. Concretely, a gpu spedup function can be slow because the input size is too small, the computation is too simple, there is excessive data copying to/from GPU/CPU, and the input types are excessivly large (e.g. np.float64 vs np.float32)\n",
    "\n",
    "Make GPU spedup ufuncs with @numba.vectorize(..., target='cuda')\n",
    "\n",
    "Make CUDA device functions with @numba.cuda.jit(device=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f38c7c-45fb-448f-923b-ca71ac41a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =====> https://numba.readthedocs.io/en/stable/cuda/examples.html#vector-addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe08ae4-894d-4e5b-b90a-3befb3af5664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12050390243530273\n",
      "0.19729042053222656\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "s = time.time()\n",
    "x_cpu = np.ones((1000,1000,100))\n",
    "e = time.time()\n",
    "print(e - s)### CuPy and GPU\n",
    "s = time.time()\n",
    "x_gpu = cp.ones((1000,1000,100))\n",
    "e = time.time()\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5095fd6d-463c-4fb2-a932-15db6fe3228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999952339622552\n",
      "0.9999952339622552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:885: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def max_example(result, values):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    bdim = cuda.blockDim.x\n",
    "    i = (bid * bdim) + tid\n",
    "    cuda.atomic.max(result, 0, values[i])\n",
    "\n",
    "\n",
    "arr = np.random.rand(16384)\n",
    "result = np.zeros(1, dtype=np.float64)\n",
    "\n",
    "max_example[256,64](result, arr)\n",
    "print(result[0]) # Found using cuda.atomic.max\n",
    "print(max(arr))  # Print max(arr) for comparison (should be equal!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a327575-a131-4570-9c57-cdc032063258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980142767371903 == 0.9980142767371903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (8) < 2 * SM count (164) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:885: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def max_example_3d(result, values):\n",
    "    \"\"\"\n",
    "    Find the maximum value in values and store in result[0].\n",
    "    Both result and values are 3d arrays.\n",
    "    \"\"\"\n",
    "    i, j, k = cuda.grid(3)\n",
    "    # Atomically store to result[0,1,2] from values[i, j, k]\n",
    "    cuda.atomic.max(result, (0, 1, 2), values[i, j, k])\n",
    "\n",
    "arr = np.random.rand(1000).reshape(10,10,10)\n",
    "result = np.zeros((3, 3, 3), dtype=np.float64)\n",
    "max_example_3d[(2, 2, 2), (5, 5, 5)](result, arr)\n",
    "print(result[0, 1, 2], '==', np.max(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a8a493-8300-4fc5-874b-98df0866e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82982d6-5019-4d44-9947-543eeeffbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def f(a, b, c):\n",
    "    # like threadIdx.x + (blockIdx.x * blockDim.x)\n",
    "    tid = cuda.grid(1)\n",
    "    size = len(c)\n",
    "\n",
    "    if tid < size:\n",
    "        c[tid] = a[tid] + b[tid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125a7917-a17e-454e-bbd7-7ed5c1c11528",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "a = cuda.to_device(np.random.random(N))\n",
    "b = cuda.to_device(np.random.random(N))\n",
    "c = cuda.device_array_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62277969-aa09-4226-8453-e307ba48b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2577078  1.42501432 0.67338825 ... 0.70452543 0.79853172 1.12594757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (131) < 2 * SM count (164) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "f.forall(len(a))(a, b, c)\n",
    "print(c.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399e146-655c-47f9-b643-7650690cbd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
