{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f875f81-a88e-4d43-be53-18fc7506b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone 8]\n",
      "[iPhone 11, iPhone 8]\n",
      "[]\n",
      "['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', \"iPhone 11 vs iPhone 8: What's the difference?\", 'I need a new phone! Any tips?']\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/models\n",
    "# https://course.spacy.io/en/chapter4\n",
    "# https://ljvmiranda921.github.io/notebook/2021/11/20/spacy-v3/\n",
    "# https://ner.pythonhumanities.com/03_02_train_spacy_ner_model.html\n",
    "\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "#with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "#    TEXTS = json.loads(f.read())\n",
    "\n",
    "TEXTS = ['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', \"iPhone 11 vs iPhone 8: What's the difference?\", 'I need a new phone! Any tips?']\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(spans)\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "print(TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1aa5f4d-4e26-4156-86f9-8ec656ded87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', \"iPhone 11 vs iPhone 8: What's the difference?\", 'I need a new phone! Any tips?']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "#with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "#    TEXTS = json.loads(f.read())\n",
    "TEXTS = ['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', \"iPhone 11 vs iPhone 8: What's the difference?\", 'I need a new phone! Any tips?']\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add patterns to the matcher\n",
    "pattern1 = ([{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}])\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"./train.spacy\")\n",
    "\n",
    "print(TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a174bb-db17-409d-a0c4-c9dc52b900e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOVEL APPROACH\n",
    "#### NOVEL APPROACH \n",
    "\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "#with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "#    TEXTS = json.loads(f.read())\n",
    "TEXTS = ['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', \"iPhone 11 vs iPhone 8: What's the difference?\", 'I need a new phone! Any tips?']\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add patterns to the matcher\n",
    "pattern1 = ([{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}])\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"./train.spacy\")\n",
    "\n",
    "print(TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203958c0-9183-43ce-8c09-121fb71bd962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config --force ./config.cfg  --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2195ac1-eab6-412d-bec6-43a4f549e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_folder"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-14 16:36:36,404] [INFO] Set up nlp object from config\n",
      "[2022-11-14 16:36:36,408] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-11-14 16:36:36,416] [INFO] Created vocabulary\n",
      "[2022-11-14 16:36:36,418] [INFO] Finished initializing nlp object\n",
      "[2022-11-14 16:36:37,529] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[i] Using GPU: 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     24.33    0.00    0.00    0.00    0.00\n",
      "200     200          2.79    340.12  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_folder\\model-last\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy train config.cfg --gpu-id 0 --paths.train train.spacy --paths.dev train.spacy --output output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5a40dd-d394-4083-87d1-7d80ec424a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_folder\n",
      "[i] Using GPU: 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     24.33    0.00    0.00    0.00    0.00\n",
      "200     200          2.79    340.12  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_folder\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-15 00:21:20,834] [INFO] Set up nlp object from config\n",
      "[2022-11-15 00:21:20,845] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-11-15 00:21:20,849] [INFO] Created vocabulary\n",
      "[2022-11-15 00:21:20,849] [INFO] Finished initializing nlp object\n",
      "[2022-11-15 00:21:21,955] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy train config.cfg --output ./output          --paths.train ./exercises/en/train_gadget.spacy --paths.dev ./exercises/en/dev_gadget.spacy\n",
    "\n",
    "!python -m spacy train config.cfg --gpu-id 0 --output ./output_folder   --paths.train ./train.spacy                     --paths.dev ./train.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80aacad7-ad0a-462c-9440-7f0934e45a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TRAINED NETWORK\n",
    "doc = nlp('Apple is slowing down the iPhone 8 and iPhone X - how to stop it')\n",
    "doc = nlp('How to preorder the iPhone X')\n",
    "for ent in doc.ents:\n",
    "    print(doc.ents)\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd6f5d8-90d2-42c3-88a9-137fcbfee53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is slowing down the iPhone 8 and iPhone X - how to stop it')\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e57f71c-6fb9-4be1-acaa-bdc7e57a6702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb3de73-b989-4325-96db-c5acebb57305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2K[+] Loaded compatibility table\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.4.2) =================\u001b[0m\n",
      "[i] spaCy installation:\n",
      "C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\n",
      "\n",
      "NAME              SPACY            VERSION      \n",
      "en_core_web_lg    >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "en_core_web_md    >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "en_core_web_sm    >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "en_core_web_trf   >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "nl_core_news_lg   >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "nl_core_news_md   >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "nl_core_news_sm   >=3.4.0,<3.5.0   3.4.0     [+]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
